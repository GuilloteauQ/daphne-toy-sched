configfile: "config/config.yaml"


url = config["zenodo_url"]
dataset = config["dataset"]
dataset_meta = config["dataset_meta"]
iterations = config["iterations"]
config_cst = config["eval_cst"]

rule all:
  input:
    "plots/all.pdf",
    "plots/cst.pdf"

rule expe_cst:
  input:
    data = f"data/{dataset}",
    script = "src/components_read.daphne",
    meta = f"data/{dataset_meta}",
  output:
    "data/CST/result_task_size_{task_size}_nb_threads_{nb_threads}.csv"
  shell:
    f"DAPHNE_CST_TASK_SIZE={{wildcards.task_size}} nix develop .#daphne-cst-shell --command daphne --vec --num-threads={{wildcards.nb_threads}} --partitioning=CST --select-matrix-representations --args f=\\\"./{{input.data}}\\\" --args iterations={iterations} {{input.script}} > {{output}}"

rule gen_plot_cst:
  input:
    script = "workflow/scripts/cst_eval.R",
    data = expand("data/CST/result_task_size_{task_size}_nb_threads_{nb_threads}.csv", nb_threads = config_cst["threads"], task_size = range(config_cst["task_size"]["start"], config_cst["task_size"]["end"], config_cst["task_size"]["step"]))
  output:
    "plots/cst.pdf"
  shell:
    "nix develop .#rshell --command Rscript {input.script} {input.data} {output}"
    

rule gen_plot:
  input:
    script = "workflow/scripts/all.R",
    data = expand("data/{policy}/all.csv", policy=config["scheduling_policies"])
  output:
    "plots/all.pdf"
  shell:
    "nix develop .#rshell --command Rscript {input.script} {input.data} {output}"

def get_csv_per_policy(wildcards):
    return expand("data/{policy}/result_nb_threads_{nb_threads}.csv", policy=wildcards.policy, nb_threads=range(config["min_threads"], config["max_threads"] + 1))

rule csv_per_policy:
  input:
    script = "workflow/scripts/analysis.R",
    data = get_csv_per_policy
  output:
    "data/{policy}/all.csv"
  shell:
    "nix develop .#rshell --command Rscript {input.script} {input.data} {wildcards.policy} {output}"
  
rule run_expe:
  input:
    data = f"data/{dataset}",
    script = "src/components_read.daphne",
    meta = f"data/{dataset_meta}",
  output:
    "data/{policy}/result_nb_threads_{nb_threads}.csv"
  shell:
    f"nix develop .#daphne-shell --command daphne --vec --num-threads={{wildcards.nb_threads}} --partitioning={{wildcards.policy}} --select-matrix-representations --args f=\\\"./{{input.data}}\\\" --args iterations={iterations} {{input.script}} > {{output}}"

rule download_dataset:
  input:
    ".md5/checkmd5.md5"
  output:
    f"data/{dataset}"
  shell:
    f"wget {url}/{dataset} -O {{output}} && md5sum -c {{input}}"

rule download_dataset_meta:
  input:
    ".md5/checkmd5_meta.md5"
  output:
    f"data/{dataset_meta}"
  shell:
    f"wget {url}/{dataset_meta} -O {{output}} && md5sum -c {{input}}"

